{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-17T11:36:37.947496Z",
     "start_time": "2025-02-17T11:36:28.257244Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.data import random_split, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T11:36:55.698440Z",
     "start_time": "2025-02-17T11:36:55.693844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_folder = './datasets/fruit_and_vegetable/train'\n",
    "class_names = sorted(os.listdir(train_folder))\n",
    "print(class_names)\n",
    "print(len(class_names))"
   ],
   "id": "a369ddc51dc0fc93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum', 'carrot', 'cauliflower', 'chilli pepper', 'corn', 'cucumber', 'eggplant', 'garlic', 'ginger', 'grapes', 'jalepeno', 'kiwi', 'lemon', 'lettuce', 'mango', 'onion', 'orange', 'paprika', 'pear', 'peas', 'pineapple', 'pomegranate', 'potato', 'raddish', 'soy beans', 'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip', 'watermelon']\n",
      "36\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T11:36:58.279913Z",
     "start_time": "2025-02-17T11:36:58.271279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
    "        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
    "        transforms.Resize(224),             # resize shortest side to 224 pixels\n",
    "        transforms.CenterCrop(224),         # crop longest side to 224 pixels at center\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "])"
   ],
   "id": "51ba808dc5424280",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T11:36:59.998266Z",
     "start_time": "2025-02-17T11:36:59.990823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, transform=transform, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.train_dir = \"./datasets/fruit_and_vegetable/train\"\n",
    "        self.valid_dir = \"./datasets/fruit_and_vegetable/validation\"\n",
    "        self.test_dir = \"./datasets/fruit_and_vegetable/test\"\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        trainset = datasets.ImageFolder(root=self.train_dir, transform=self.transform)\n",
    "        validset = datasets.ImageFolder(root=self.valid_dir, transform=self.transform)\n",
    "        testset = datasets.ImageFolder(root=self.test_dir, transform=self.transform)\n",
    "        \n",
    "        self.trainloader = DataLoader(trainset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.validloader = DataLoader(validset, batch_size=self.batch_size)\n",
    "        self.testloader = DataLoader(testset, batch_size=self.batch_size)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return self.trainloader\n",
    "    \n",
    "    def valid_dataloader(self):\n",
    "        return self.validloader\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.testloader"
   ],
   "id": "35f5a4cf68877f9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T11:37:02.021500Z",
     "start_time": "2025-02-17T11:37:02.010702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConvolutionalNetwork(LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(16 * 54 * 54, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 20)\n",
    "        self.fc4 = nn.Linear(20, len(class_names))\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 16 * 54 * 54)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = F.relu(self.fc3(X))\n",
    "        X = self.fc4(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.004)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        X, y = train_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        X, y = val_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        X, y = test_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)"
   ],
   "id": "21ec714c25aa91a1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-17T11:37:04.828975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    datamodule = DataModule()\n",
    "    datamodule.setup()\n",
    "    model = ConvolutionalNetwork()\n",
    "    trainer = pl.Trainer(max_epochs=40)\n",
    "    trainer.fit(model, datamodule) \n",
    "    datamodule.setup(stage='test') \n",
    "    trainer.test(dataloaders=datamodule.test_dataloader())"
   ],
   "id": "685b7eb488586cce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "D:\\Development\\Anaconda\\envs\\ai\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "D:\\Development\\Anaconda\\envs\\ai\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | conv1 | Conv2d | 168    | train\n",
      "1 | conv2 | Conv2d | 880    | train\n",
      "2 | fc1   | Linear | 5.6 M  | train\n",
      "3 | fc2   | Linear | 10.2 K | train\n",
      "4 | fc3   | Linear | 1.7 K  | train\n",
      "5 | fc4   | Linear | 756    | train\n",
      "-----------------------------------------\n",
      "5.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 M     Total params\n",
      "22.450    Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "D:\\Development\\Anaconda\\envs\\ai\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc95307a491549c9936fd660664a64d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\Anaconda\\envs\\ai\\Lib\\site-packages\\PIL\\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for images, labels in datamodule.test_dataloader():\n",
    "    break\n",
    "im=make_grid(images,nrow=16)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(np.transpose(im.numpy(),(1,2,0)))\n",
    "inv_normalize=transforms.Normalize(mean=[-0.485/0.229,-0.456/0.224,-0.406/0.225],\n",
    "                                   std=[1/0.229,1/0.224,1/0.225])\n",
    "im=inv_normalize(im)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
   ],
   "id": "62202dc156d70839"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device(\"cpu\") #\"cuda:0\"\n",
    "\n",
    "model.eval()\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "with torch.no_grad():\n",
    "    for test_data in datamodule.test_dataloader():\n",
    "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n",
    "\n",
    "print(classification_report(y_true,y_pred,target_names=class_names,digits=4))"
   ],
   "id": "595154100c179e01"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
